# People Counting System

A real-time people counting and analytics system using computer vision, capable of detecting people, classifying gender, and tracking movement across a virtual line. Supports both live webcam input and video file uploads with comprehensive statistics.

## ğŸš€ Features

- **Real-time Person Detection**: Uses YOLOv8 for accurate person detection
- **Gender Classification**: Distinguishes between male and female individuals
- **Object Tracking**: Centroid-based tracking for consistent identification
- **Directional Counting**: Tracks entry/exit movements across a configurable line
- **Live Analytics Dashboard**: Real-time statistics with gender breakdown
- **Dual Input Support**: Webcam streaming via WebSocket and video file uploads
- **Modern Web Interface**: Built with Next.js and Tailwind CSS
- **RESTful API**: FastAPI backend with comprehensive endpoints

## ğŸ—ï¸ Project Structure

```
people-counting/
â”œâ”€â”€ backend/                          # FastAPI Backend
â”‚   â”œâ”€â”€ app.py                       # Main FastAPI application
â”‚   â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚   â”œâ”€â”€ gender-cls.pt               # Gender classification model
â”‚   â”œâ”€â”€ yolov8n.pt                  # YOLOv8 person detection model
â”‚   â””â”€â”€ train.py                    # Model training script
â”œâ”€â”€ frontend/                        # Next.js Frontend
â”‚   â”œâ”€â”€ app/                        # Next.js 13+ app directory
â”‚   â”‚   â”œâ”€â”€ api/                    # API routes
â”‚   â”‚   â”œâ”€â”€ globals.css             # Global styles
â”‚   â”‚   â”œâ”€â”€ layout.tsx              # Root layout
â”‚   â”‚   â””â”€â”€ page.tsx                # Home page
â”‚   â”œâ”€â”€ components/                 # React components
â”‚   â”‚   â”œâ”€â”€ ui/                     # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ live-analytics.tsx      # Main analytics component
â”‚   â”‚   â”œâ”€â”€ stats-dashboard.tsx     # Statistics display
â”‚   â”‚   â”œâ”€â”€ video-renderer.tsx      # Video display with overlays
â”‚   â”‚   â””â”€â”€ video-input-selector.tsx # Input method selector
â”‚   â”œâ”€â”€ lib/                        # Utility libraries
â”‚   â”‚   â”œâ”€â”€ detection-client.ts     # Backend communication client
â”‚   â”‚   â”œâ”€â”€ centroid-tracker.ts     # Client-side tracking
â”‚   â”‚   â””â”€â”€ yolo-processor.ts       # YOLO processing utilities
â”‚   â””â”€â”€ public/                     # Static assets
â”œâ”€â”€ human-walking-ground-truth-main/ # Sample videos for testing
â””â”€â”€ README.md                       # This file
```

## ğŸ› ï¸ Technologies Used

### Backend
- **FastAPI**: High-performance async web framework
- **OpenCV**: Computer vision library
- **Ultralytics YOLO**: State-of-the-art object detection
- **NumPy**: Numerical computing
- **WebSocket**: Real-time bidirectional communication

### Frontend
- **Next.js 14**: React framework with app directory
- **TypeScript**: Type-safe JavaScript
- **Tailwind CSS**: Utility-first CSS framework
- **Lucide React**: Beautiful icons
- **WebRTC**: Browser media capture

## ğŸ“‹ Prerequisites

- **Python 3.8+**: For backend processing
- **Node.js 18+**: For frontend development
- **Webcam**: For real-time video input (optional for file uploads)
- **Git**: For cloning the repository

## ğŸš€ Installation & Setup

### 1. Clone the Repository

```bash
git clone <repository-url>
cd people-counting
```

### 2. Backend Setup

```bash
# Navigate to backend directory
cd backend

# Create virtual environment (recommended)
python -m venv venv
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 3. Frontend Setup

```bash
# Navigate to frontend directory
cd ../frontend

# Install dependencies
npm install
# or if using pnpm
pnpm install
```

## â–¶ï¸ Running the Application

### Start Backend Server

```bash
cd backend
python app.py
```

The backend will start on `http://localhost:5000`

### Start Frontend Server

```bash
cd frontend
npm run dev
```

The frontend will start on `http://localhost:3000`

## ğŸ“– Usage

1. **Open the Application**: Navigate to `http://localhost:3000` in your browser

2. **Choose Input Method**:
   - **Webcam**: Click "Webcam" for real-time processing
   - **Upload**: Click "Upload" to select a video file

3. **View Analytics**: Watch live detections and statistics update in real-time

4. **Monitor Statistics**:
   - Current people count
   - Gender breakdown (male/female)
   - Entry/exit counts by gender

## ğŸ”Œ API Reference

### Backend Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/process-video` | Process uploaded video file |
| `GET` | `/api/stats` | Get current statistics |
| `GET` | `/api/stream` | Server-sent events for stats (legacy) |
| `GET` | `/api/health` | Health check endpoint |
| `WS` | `/ws` | WebSocket for real-time frame processing |

### Frontend API Routes

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/health` | Backend health check proxy |
| `POST` | `/api/process-video` | Video processing proxy |
| `GET` | `/api/stats` | Statistics proxy |
| `GET` | `/api/stream` | Stream proxy |
| `GET` | `/api/ws` | WebSocket proxy (placeholder) |

## ğŸ¯ How It Works

### Detection Pipeline
1. **Input Capture**: Webcam frames or video file frames
2. **Person Detection**: YOLOv8 identifies people in the frame
3. **Gender Classification**: Custom model classifies gender for each detection
4. **Object Tracking**: Centroid tracker maintains identity across frames
5. **Counting Logic**: Tracks movement across a virtual line
6. **Statistics Update**: Real-time metrics calculation

### Real-time Processing
- **Webcam**: Frames captured via `getUserMedia`, sent to backend via WebSocket
- **Video Files**: Processed frame-by-frame on upload
- **Tracking**: Maintains object identity using centroid distances
- **Counting**: Direction-based counting with cooldown to prevent double-counting

## ğŸ§ª Testing

Sample videos are included in `human-walking-ground-truth-main/` for testing:

```bash
# Use any of the walk*.MP4 files for testing
```

## ğŸ”§ Configuration

### Backend Configuration
- **Detection Confidence**: Configurable in `app.py` (default: 0.4)
- **Tracking Parameters**: Max disappearance frames in `CentroidTracker`
- **Line Position**: Automatically set to frame center

### Frontend Configuration
- **Video Resolution**: Ideal 1280x720 for webcam
- **Frame Rate**: Browser-dependent, typically 30 FPS
- **WebSocket URL**: Configurable in `detection-client.ts`

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.


**Note**: This system requires significant computational resources for real-time processing. Performance may vary based on hardware capabilities.
